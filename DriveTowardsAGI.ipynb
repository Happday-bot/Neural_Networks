{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw13l9JfIzzT6E4q1VSbRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Happday-bot/Neural_Networks/blob/main/DriveTowardsAGI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here the model is tried in such a way that you no need to define the neural size, or the number of units needed**\n",
        "\n",
        "# Let the model do alll those work for you while you just tell it what activation function to use for all layers except for the last one as it is softmax if the model is classification or it defaults to the selected activation function"
      ],
      "metadata": {
        "id": "HUItMTyKoC1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The code is used from the Updated classfiynumber.ipynb of this github account**"
      ],
      "metadata": {
        "id": "IrsqimqooveU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "ClwTaHtkqsvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
      ],
      "metadata": {
        "id": "keaJuQHpE9PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "x = iris.drop('species', axis=1).values\n",
        "y = iris['species']\n",
        "\n",
        "y = np.array(y)\n",
        "for i in range(len(y)):\n",
        "  if y[i] == 'setosa':\n",
        "    y[i] = [1,0,0]\n",
        "  elif y[i] == 'versicolor':\n",
        "    y[i] = [0,1,0]\n",
        "  else:\n",
        "    y[i] = [0,0,1]"
      ],
      "metadata": {
        "id": "Fn76CDXRwPnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "8_NC22zVwkvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aacb220-01e7-4453-f42c-b8176656cee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual_input = x.tolist()\n",
        "actual_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqopVwf0E0E9",
        "outputId": "588dd74d-0c3b-4f98-aaac-0a5d903311cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5.1, 3.5, 1.4, 0.2],\n",
              " [4.9, 3.0, 1.4, 0.2],\n",
              " [4.7, 3.2, 1.3, 0.2],\n",
              " [4.6, 3.1, 1.5, 0.2],\n",
              " [5.0, 3.6, 1.4, 0.2],\n",
              " [5.4, 3.9, 1.7, 0.4],\n",
              " [4.6, 3.4, 1.4, 0.3],\n",
              " [5.0, 3.4, 1.5, 0.2],\n",
              " [4.4, 2.9, 1.4, 0.2],\n",
              " [4.9, 3.1, 1.5, 0.1],\n",
              " [5.4, 3.7, 1.5, 0.2],\n",
              " [4.8, 3.4, 1.6, 0.2],\n",
              " [4.8, 3.0, 1.4, 0.1],\n",
              " [4.3, 3.0, 1.1, 0.1],\n",
              " [5.8, 4.0, 1.2, 0.2],\n",
              " [5.7, 4.4, 1.5, 0.4],\n",
              " [5.4, 3.9, 1.3, 0.4],\n",
              " [5.1, 3.5, 1.4, 0.3],\n",
              " [5.7, 3.8, 1.7, 0.3],\n",
              " [5.1, 3.8, 1.5, 0.3],\n",
              " [5.4, 3.4, 1.7, 0.2],\n",
              " [5.1, 3.7, 1.5, 0.4],\n",
              " [4.6, 3.6, 1.0, 0.2],\n",
              " [5.1, 3.3, 1.7, 0.5],\n",
              " [4.8, 3.4, 1.9, 0.2],\n",
              " [5.0, 3.0, 1.6, 0.2],\n",
              " [5.0, 3.4, 1.6, 0.4],\n",
              " [5.2, 3.5, 1.5, 0.2],\n",
              " [5.2, 3.4, 1.4, 0.2],\n",
              " [4.7, 3.2, 1.6, 0.2],\n",
              " [4.8, 3.1, 1.6, 0.2],\n",
              " [5.4, 3.4, 1.5, 0.4],\n",
              " [5.2, 4.1, 1.5, 0.1],\n",
              " [5.5, 4.2, 1.4, 0.2],\n",
              " [4.9, 3.1, 1.5, 0.2],\n",
              " [5.0, 3.2, 1.2, 0.2],\n",
              " [5.5, 3.5, 1.3, 0.2],\n",
              " [4.9, 3.6, 1.4, 0.1],\n",
              " [4.4, 3.0, 1.3, 0.2],\n",
              " [5.1, 3.4, 1.5, 0.2],\n",
              " [5.0, 3.5, 1.3, 0.3],\n",
              " [4.5, 2.3, 1.3, 0.3],\n",
              " [4.4, 3.2, 1.3, 0.2],\n",
              " [5.0, 3.5, 1.6, 0.6],\n",
              " [5.1, 3.8, 1.9, 0.4],\n",
              " [4.8, 3.0, 1.4, 0.3],\n",
              " [5.1, 3.8, 1.6, 0.2],\n",
              " [4.6, 3.2, 1.4, 0.2],\n",
              " [5.3, 3.7, 1.5, 0.2],\n",
              " [5.0, 3.3, 1.4, 0.2],\n",
              " [7.0, 3.2, 4.7, 1.4],\n",
              " [6.4, 3.2, 4.5, 1.5],\n",
              " [6.9, 3.1, 4.9, 1.5],\n",
              " [5.5, 2.3, 4.0, 1.3],\n",
              " [6.5, 2.8, 4.6, 1.5],\n",
              " [5.7, 2.8, 4.5, 1.3],\n",
              " [6.3, 3.3, 4.7, 1.6],\n",
              " [4.9, 2.4, 3.3, 1.0],\n",
              " [6.6, 2.9, 4.6, 1.3],\n",
              " [5.2, 2.7, 3.9, 1.4],\n",
              " [5.0, 2.0, 3.5, 1.0],\n",
              " [5.9, 3.0, 4.2, 1.5],\n",
              " [6.0, 2.2, 4.0, 1.0],\n",
              " [6.1, 2.9, 4.7, 1.4],\n",
              " [5.6, 2.9, 3.6, 1.3],\n",
              " [6.7, 3.1, 4.4, 1.4],\n",
              " [5.6, 3.0, 4.5, 1.5],\n",
              " [5.8, 2.7, 4.1, 1.0],\n",
              " [6.2, 2.2, 4.5, 1.5],\n",
              " [5.6, 2.5, 3.9, 1.1],\n",
              " [5.9, 3.2, 4.8, 1.8],\n",
              " [6.1, 2.8, 4.0, 1.3],\n",
              " [6.3, 2.5, 4.9, 1.5],\n",
              " [6.1, 2.8, 4.7, 1.2],\n",
              " [6.4, 2.9, 4.3, 1.3],\n",
              " [6.6, 3.0, 4.4, 1.4],\n",
              " [6.8, 2.8, 4.8, 1.4],\n",
              " [6.7, 3.0, 5.0, 1.7],\n",
              " [6.0, 2.9, 4.5, 1.5],\n",
              " [5.7, 2.6, 3.5, 1.0],\n",
              " [5.5, 2.4, 3.8, 1.1],\n",
              " [5.5, 2.4, 3.7, 1.0],\n",
              " [5.8, 2.7, 3.9, 1.2],\n",
              " [6.0, 2.7, 5.1, 1.6],\n",
              " [5.4, 3.0, 4.5, 1.5],\n",
              " [6.0, 3.4, 4.5, 1.6],\n",
              " [6.7, 3.1, 4.7, 1.5],\n",
              " [6.3, 2.3, 4.4, 1.3],\n",
              " [5.6, 3.0, 4.1, 1.3],\n",
              " [5.5, 2.5, 4.0, 1.3],\n",
              " [5.5, 2.6, 4.4, 1.2],\n",
              " [6.1, 3.0, 4.6, 1.4],\n",
              " [5.8, 2.6, 4.0, 1.2],\n",
              " [5.0, 2.3, 3.3, 1.0],\n",
              " [5.6, 2.7, 4.2, 1.3],\n",
              " [5.7, 3.0, 4.2, 1.2],\n",
              " [5.7, 2.9, 4.2, 1.3],\n",
              " [6.2, 2.9, 4.3, 1.3],\n",
              " [5.1, 2.5, 3.0, 1.1],\n",
              " [5.7, 2.8, 4.1, 1.3],\n",
              " [6.3, 3.3, 6.0, 2.5],\n",
              " [5.8, 2.7, 5.1, 1.9],\n",
              " [7.1, 3.0, 5.9, 2.1],\n",
              " [6.3, 2.9, 5.6, 1.8],\n",
              " [6.5, 3.0, 5.8, 2.2],\n",
              " [7.6, 3.0, 6.6, 2.1],\n",
              " [4.9, 2.5, 4.5, 1.7],\n",
              " [7.3, 2.9, 6.3, 1.8],\n",
              " [6.7, 2.5, 5.8, 1.8],\n",
              " [7.2, 3.6, 6.1, 2.5],\n",
              " [6.5, 3.2, 5.1, 2.0],\n",
              " [6.4, 2.7, 5.3, 1.9],\n",
              " [6.8, 3.0, 5.5, 2.1],\n",
              " [5.7, 2.5, 5.0, 2.0],\n",
              " [5.8, 2.8, 5.1, 2.4],\n",
              " [6.4, 3.2, 5.3, 2.3],\n",
              " [6.5, 3.0, 5.5, 1.8],\n",
              " [7.7, 3.8, 6.7, 2.2],\n",
              " [7.7, 2.6, 6.9, 2.3],\n",
              " [6.0, 2.2, 5.0, 1.5],\n",
              " [6.9, 3.2, 5.7, 2.3],\n",
              " [5.6, 2.8, 4.9, 2.0],\n",
              " [7.7, 2.8, 6.7, 2.0],\n",
              " [6.3, 2.7, 4.9, 1.8],\n",
              " [6.7, 3.3, 5.7, 2.1],\n",
              " [7.2, 3.2, 6.0, 1.8],\n",
              " [6.2, 2.8, 4.8, 1.8],\n",
              " [6.1, 3.0, 4.9, 1.8],\n",
              " [6.4, 2.8, 5.6, 2.1],\n",
              " [7.2, 3.0, 5.8, 1.6],\n",
              " [7.4, 2.8, 6.1, 1.9],\n",
              " [7.9, 3.8, 6.4, 2.0],\n",
              " [6.4, 2.8, 5.6, 2.2],\n",
              " [6.3, 2.8, 5.1, 1.5],\n",
              " [6.1, 2.6, 5.6, 1.4],\n",
              " [7.7, 3.0, 6.1, 2.3],\n",
              " [6.3, 3.4, 5.6, 2.4],\n",
              " [6.4, 3.1, 5.5, 1.8],\n",
              " [6.0, 3.0, 4.8, 1.8],\n",
              " [6.9, 3.1, 5.4, 2.1],\n",
              " [6.7, 3.1, 5.6, 2.4],\n",
              " [6.9, 3.1, 5.1, 2.3],\n",
              " [5.8, 2.7, 5.1, 1.9],\n",
              " [6.8, 3.2, 5.9, 2.3],\n",
              " [6.7, 3.3, 5.7, 2.5],\n",
              " [6.7, 3.0, 5.2, 2.3],\n",
              " [6.3, 2.5, 5.0, 1.9],\n",
              " [6.5, 3.0, 5.2, 2.0],\n",
              " [6.2, 3.4, 5.4, 2.3],\n",
              " [5.9, 3.0, 5.1, 1.8]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldu_xZ-eFRDZ",
        "outputId": "fbe9162d-aba7-48e6-cf4b-1a06ac147d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]), list([1, 0, 0]),\n",
              "       list([1, 0, 0]), list([1, 0, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]), list([0, 1, 0]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]), list([0, 0, 1]),\n",
              "       list([0, 0, 1]), list([0, 0, 1])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual_output = y.tolist()\n",
        "actual_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfKWIdrfFUs7",
        "outputId": "49f2d7b3-a6d9-4285-d945-33386e41eafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {}\n",
        "for i in range(len(actual_output)):\n",
        "  data[tuple(actual_input[i])] = actual_output[i]\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khuXfcVNFqOy",
        "outputId": "62272156-16a7-45e8-e2f0-5f867380655c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(5.1, 3.5, 1.4, 0.2): [1, 0, 0],\n",
              " (4.9, 3.0, 1.4, 0.2): [1, 0, 0],\n",
              " (4.7, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (4.6, 3.1, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.6, 1.4, 0.2): [1, 0, 0],\n",
              " (5.4, 3.9, 1.7, 0.4): [1, 0, 0],\n",
              " (4.6, 3.4, 1.4, 0.3): [1, 0, 0],\n",
              " (5.0, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (4.4, 2.9, 1.4, 0.2): [1, 0, 0],\n",
              " (4.9, 3.1, 1.5, 0.1): [1, 0, 0],\n",
              " (5.4, 3.7, 1.5, 0.2): [1, 0, 0],\n",
              " (4.8, 3.4, 1.6, 0.2): [1, 0, 0],\n",
              " (4.8, 3.0, 1.4, 0.1): [1, 0, 0],\n",
              " (4.3, 3.0, 1.1, 0.1): [1, 0, 0],\n",
              " (5.8, 4.0, 1.2, 0.2): [1, 0, 0],\n",
              " (5.7, 4.4, 1.5, 0.4): [1, 0, 0],\n",
              " (5.4, 3.9, 1.3, 0.4): [1, 0, 0],\n",
              " (5.1, 3.5, 1.4, 0.3): [1, 0, 0],\n",
              " (5.7, 3.8, 1.7, 0.3): [1, 0, 0],\n",
              " (5.1, 3.8, 1.5, 0.3): [1, 0, 0],\n",
              " (5.4, 3.4, 1.7, 0.2): [1, 0, 0],\n",
              " (5.1, 3.7, 1.5, 0.4): [1, 0, 0],\n",
              " (4.6, 3.6, 1.0, 0.2): [1, 0, 0],\n",
              " (5.1, 3.3, 1.7, 0.5): [1, 0, 0],\n",
              " (4.8, 3.4, 1.9, 0.2): [1, 0, 0],\n",
              " (5.0, 3.0, 1.6, 0.2): [1, 0, 0],\n",
              " (5.0, 3.4, 1.6, 0.4): [1, 0, 0],\n",
              " (5.2, 3.5, 1.5, 0.2): [1, 0, 0],\n",
              " (5.2, 3.4, 1.4, 0.2): [1, 0, 0],\n",
              " (4.7, 3.2, 1.6, 0.2): [1, 0, 0],\n",
              " (4.8, 3.1, 1.6, 0.2): [1, 0, 0],\n",
              " (5.4, 3.4, 1.5, 0.4): [1, 0, 0],\n",
              " (5.2, 4.1, 1.5, 0.1): [1, 0, 0],\n",
              " (5.5, 4.2, 1.4, 0.2): [1, 0, 0],\n",
              " (4.9, 3.1, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.2, 1.2, 0.2): [1, 0, 0],\n",
              " (5.5, 3.5, 1.3, 0.2): [1, 0, 0],\n",
              " (4.9, 3.6, 1.4, 0.1): [1, 0, 0],\n",
              " (4.4, 3.0, 1.3, 0.2): [1, 0, 0],\n",
              " (5.1, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.5, 1.3, 0.3): [1, 0, 0],\n",
              " (4.5, 2.3, 1.3, 0.3): [1, 0, 0],\n",
              " (4.4, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (5.0, 3.5, 1.6, 0.6): [1, 0, 0],\n",
              " (5.1, 3.8, 1.9, 0.4): [1, 0, 0],\n",
              " (4.8, 3.0, 1.4, 0.3): [1, 0, 0],\n",
              " (5.1, 3.8, 1.6, 0.2): [1, 0, 0],\n",
              " (4.6, 3.2, 1.4, 0.2): [1, 0, 0],\n",
              " (5.3, 3.7, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.3, 1.4, 0.2): [1, 0, 0],\n",
              " (7.0, 3.2, 4.7, 1.4): [0, 1, 0],\n",
              " (6.4, 3.2, 4.5, 1.5): [0, 1, 0],\n",
              " (6.9, 3.1, 4.9, 1.5): [0, 1, 0],\n",
              " (5.5, 2.3, 4.0, 1.3): [0, 1, 0],\n",
              " (6.5, 2.8, 4.6, 1.5): [0, 1, 0],\n",
              " (5.7, 2.8, 4.5, 1.3): [0, 1, 0],\n",
              " (6.3, 3.3, 4.7, 1.6): [0, 1, 0],\n",
              " (4.9, 2.4, 3.3, 1.0): [0, 1, 0],\n",
              " (6.6, 2.9, 4.6, 1.3): [0, 1, 0],\n",
              " (5.2, 2.7, 3.9, 1.4): [0, 1, 0],\n",
              " (5.0, 2.0, 3.5, 1.0): [0, 1, 0],\n",
              " (5.9, 3.0, 4.2, 1.5): [0, 1, 0],\n",
              " (6.0, 2.2, 4.0, 1.0): [0, 1, 0],\n",
              " (6.1, 2.9, 4.7, 1.4): [0, 1, 0],\n",
              " (5.6, 2.9, 3.6, 1.3): [0, 1, 0],\n",
              " (6.7, 3.1, 4.4, 1.4): [0, 1, 0],\n",
              " (5.6, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (5.8, 2.7, 4.1, 1.0): [0, 1, 0],\n",
              " (6.2, 2.2, 4.5, 1.5): [0, 1, 0],\n",
              " (5.6, 2.5, 3.9, 1.1): [0, 1, 0],\n",
              " (5.9, 3.2, 4.8, 1.8): [0, 1, 0],\n",
              " (6.1, 2.8, 4.0, 1.3): [0, 1, 0],\n",
              " (6.3, 2.5, 4.9, 1.5): [0, 1, 0],\n",
              " (6.1, 2.8, 4.7, 1.2): [0, 1, 0],\n",
              " (6.4, 2.9, 4.3, 1.3): [0, 1, 0],\n",
              " (6.6, 3.0, 4.4, 1.4): [0, 1, 0],\n",
              " (6.8, 2.8, 4.8, 1.4): [0, 1, 0],\n",
              " (6.7, 3.0, 5.0, 1.7): [0, 1, 0],\n",
              " (6.0, 2.9, 4.5, 1.5): [0, 1, 0],\n",
              " (5.7, 2.6, 3.5, 1.0): [0, 1, 0],\n",
              " (5.5, 2.4, 3.8, 1.1): [0, 1, 0],\n",
              " (5.5, 2.4, 3.7, 1.0): [0, 1, 0],\n",
              " (5.8, 2.7, 3.9, 1.2): [0, 1, 0],\n",
              " (6.0, 2.7, 5.1, 1.6): [0, 1, 0],\n",
              " (5.4, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (6.0, 3.4, 4.5, 1.6): [0, 1, 0],\n",
              " (6.7, 3.1, 4.7, 1.5): [0, 1, 0],\n",
              " (6.3, 2.3, 4.4, 1.3): [0, 1, 0],\n",
              " (5.6, 3.0, 4.1, 1.3): [0, 1, 0],\n",
              " (5.5, 2.5, 4.0, 1.3): [0, 1, 0],\n",
              " (5.5, 2.6, 4.4, 1.2): [0, 1, 0],\n",
              " (6.1, 3.0, 4.6, 1.4): [0, 1, 0],\n",
              " (5.8, 2.6, 4.0, 1.2): [0, 1, 0],\n",
              " (5.0, 2.3, 3.3, 1.0): [0, 1, 0],\n",
              " (5.6, 2.7, 4.2, 1.3): [0, 1, 0],\n",
              " (5.7, 3.0, 4.2, 1.2): [0, 1, 0],\n",
              " (5.7, 2.9, 4.2, 1.3): [0, 1, 0],\n",
              " (6.2, 2.9, 4.3, 1.3): [0, 1, 0],\n",
              " (5.1, 2.5, 3.0, 1.1): [0, 1, 0],\n",
              " (5.7, 2.8, 4.1, 1.3): [0, 1, 0],\n",
              " (6.3, 3.3, 6.0, 2.5): [0, 0, 1],\n",
              " (5.8, 2.7, 5.1, 1.9): [0, 0, 1],\n",
              " (7.1, 3.0, 5.9, 2.1): [0, 0, 1],\n",
              " (6.3, 2.9, 5.6, 1.8): [0, 0, 1],\n",
              " (6.5, 3.0, 5.8, 2.2): [0, 0, 1],\n",
              " (7.6, 3.0, 6.6, 2.1): [0, 0, 1],\n",
              " (4.9, 2.5, 4.5, 1.7): [0, 0, 1],\n",
              " (7.3, 2.9, 6.3, 1.8): [0, 0, 1],\n",
              " (6.7, 2.5, 5.8, 1.8): [0, 0, 1],\n",
              " (7.2, 3.6, 6.1, 2.5): [0, 0, 1],\n",
              " (6.5, 3.2, 5.1, 2.0): [0, 0, 1],\n",
              " (6.4, 2.7, 5.3, 1.9): [0, 0, 1],\n",
              " (6.8, 3.0, 5.5, 2.1): [0, 0, 1],\n",
              " (5.7, 2.5, 5.0, 2.0): [0, 0, 1],\n",
              " (5.8, 2.8, 5.1, 2.4): [0, 0, 1],\n",
              " (6.4, 3.2, 5.3, 2.3): [0, 0, 1],\n",
              " (6.5, 3.0, 5.5, 1.8): [0, 0, 1],\n",
              " (7.7, 3.8, 6.7, 2.2): [0, 0, 1],\n",
              " (7.7, 2.6, 6.9, 2.3): [0, 0, 1],\n",
              " (6.0, 2.2, 5.0, 1.5): [0, 0, 1],\n",
              " (6.9, 3.2, 5.7, 2.3): [0, 0, 1],\n",
              " (5.6, 2.8, 4.9, 2.0): [0, 0, 1],\n",
              " (7.7, 2.8, 6.7, 2.0): [0, 0, 1],\n",
              " (6.3, 2.7, 4.9, 1.8): [0, 0, 1],\n",
              " (6.7, 3.3, 5.7, 2.1): [0, 0, 1],\n",
              " (7.2, 3.2, 6.0, 1.8): [0, 0, 1],\n",
              " (6.2, 2.8, 4.8, 1.8): [0, 0, 1],\n",
              " (6.1, 3.0, 4.9, 1.8): [0, 0, 1],\n",
              " (6.4, 2.8, 5.6, 2.1): [0, 0, 1],\n",
              " (7.2, 3.0, 5.8, 1.6): [0, 0, 1],\n",
              " (7.4, 2.8, 6.1, 1.9): [0, 0, 1],\n",
              " (7.9, 3.8, 6.4, 2.0): [0, 0, 1],\n",
              " (6.4, 2.8, 5.6, 2.2): [0, 0, 1],\n",
              " (6.3, 2.8, 5.1, 1.5): [0, 0, 1],\n",
              " (6.1, 2.6, 5.6, 1.4): [0, 0, 1],\n",
              " (7.7, 3.0, 6.1, 2.3): [0, 0, 1],\n",
              " (6.3, 3.4, 5.6, 2.4): [0, 0, 1],\n",
              " (6.4, 3.1, 5.5, 1.8): [0, 0, 1],\n",
              " (6.0, 3.0, 4.8, 1.8): [0, 0, 1],\n",
              " (6.9, 3.1, 5.4, 2.1): [0, 0, 1],\n",
              " (6.7, 3.1, 5.6, 2.4): [0, 0, 1],\n",
              " (6.9, 3.1, 5.1, 2.3): [0, 0, 1],\n",
              " (6.8, 3.2, 5.9, 2.3): [0, 0, 1],\n",
              " (6.7, 3.3, 5.7, 2.5): [0, 0, 1],\n",
              " (6.7, 3.0, 5.2, 2.3): [0, 0, 1],\n",
              " (6.3, 2.5, 5.0, 1.9): [0, 0, 1],\n",
              " (6.5, 3.0, 5.2, 2.0): [0, 0, 1],\n",
              " (6.2, 3.4, 5.4, 2.3): [0, 0, 1],\n",
              " (5.9, 3.0, 5.1, 1.8): [0, 0, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_dict(data):\n",
        "    keys = list(data.keys())\n",
        "    random.shuffle(keys)\n",
        "    return {k: data[k] for k in keys}"
      ],
      "metadata": {
        "id": "5bwHRZNCGA6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = shuffle_dict(data)"
      ],
      "metadata": {
        "id": "-rUiaL5wGvIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rxhutBIIFol",
        "outputId": "91e9e40d-28a7-4f87-a2c4-81dd1241eec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(4.8, 3.4, 1.6, 0.2): [1, 0, 0],\n",
              " (5.4, 3.9, 1.3, 0.4): [1, 0, 0],\n",
              " (5.0, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (6.4, 3.1, 5.5, 1.8): [0, 0, 1],\n",
              " (5.4, 3.9, 1.7, 0.4): [1, 0, 0],\n",
              " (6.3, 2.9, 5.6, 1.8): [0, 0, 1],\n",
              " (6.7, 3.1, 5.6, 2.4): [0, 0, 1],\n",
              " (6.0, 2.2, 4.0, 1.0): [0, 1, 0],\n",
              " (5.6, 2.7, 4.2, 1.3): [0, 1, 0],\n",
              " (5.1, 3.5, 1.4, 0.2): [1, 0, 0],\n",
              " (5.0, 3.2, 1.2, 0.2): [1, 0, 0],\n",
              " (4.9, 3.1, 1.5, 0.1): [1, 0, 0],\n",
              " (6.5, 3.0, 5.8, 2.2): [0, 0, 1],\n",
              " (5.8, 2.8, 5.1, 2.4): [0, 0, 1],\n",
              " (5.5, 2.4, 3.8, 1.1): [0, 1, 0],\n",
              " (5.9, 3.0, 4.2, 1.5): [0, 1, 0],\n",
              " (6.7, 3.1, 4.7, 1.5): [0, 1, 0],\n",
              " (6.8, 3.0, 5.5, 2.1): [0, 0, 1],\n",
              " (6.9, 3.1, 4.9, 1.5): [0, 1, 0],\n",
              " (5.0, 3.4, 1.6, 0.4): [1, 0, 0],\n",
              " (4.9, 2.4, 3.3, 1.0): [0, 1, 0],\n",
              " (5.1, 3.3, 1.7, 0.5): [1, 0, 0],\n",
              " (6.7, 3.3, 5.7, 2.1): [0, 0, 1],\n",
              " (4.8, 3.0, 1.4, 0.3): [1, 0, 0],\n",
              " (6.0, 2.2, 5.0, 1.5): [0, 0, 1],\n",
              " (6.6, 2.9, 4.6, 1.3): [0, 1, 0],\n",
              " (5.0, 3.3, 1.4, 0.2): [1, 0, 0],\n",
              " (6.1, 2.8, 4.0, 1.3): [0, 1, 0],\n",
              " (5.5, 2.4, 3.7, 1.0): [0, 1, 0],\n",
              " (4.4, 2.9, 1.4, 0.2): [1, 0, 0],\n",
              " (6.0, 2.9, 4.5, 1.5): [0, 1, 0],\n",
              " (7.7, 2.6, 6.9, 2.3): [0, 0, 1],\n",
              " (5.7, 3.0, 4.2, 1.2): [0, 1, 0],\n",
              " (7.2, 3.0, 5.8, 1.6): [0, 0, 1],\n",
              " (4.8, 3.4, 1.9, 0.2): [1, 0, 0],\n",
              " (5.0, 2.0, 3.5, 1.0): [0, 1, 0],\n",
              " (4.6, 3.1, 1.5, 0.2): [1, 0, 0],\n",
              " (5.8, 2.7, 3.9, 1.2): [0, 1, 0],\n",
              " (5.8, 2.7, 5.1, 1.9): [0, 0, 1],\n",
              " (6.4, 3.2, 4.5, 1.5): [0, 1, 0],\n",
              " (5.5, 2.5, 4.0, 1.3): [0, 1, 0],\n",
              " (5.1, 3.8, 1.6, 0.2): [1, 0, 0],\n",
              " (6.4, 2.8, 5.6, 2.2): [0, 0, 1],\n",
              " (5.5, 2.3, 4.0, 1.3): [0, 1, 0],\n",
              " (5.1, 2.5, 3.0, 1.1): [0, 1, 0],\n",
              " (5.1, 3.7, 1.5, 0.4): [1, 0, 0],\n",
              " (7.2, 3.6, 6.1, 2.5): [0, 0, 1],\n",
              " (6.5, 2.8, 4.6, 1.5): [0, 1, 0],\n",
              " (6.1, 2.8, 4.7, 1.2): [0, 1, 0],\n",
              " (6.3, 2.7, 4.9, 1.8): [0, 0, 1],\n",
              " (4.4, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (5.2, 4.1, 1.5, 0.1): [1, 0, 0],\n",
              " (4.6, 3.6, 1.0, 0.2): [1, 0, 0],\n",
              " (6.3, 3.3, 4.7, 1.6): [0, 1, 0],\n",
              " (6.7, 3.3, 5.7, 2.5): [0, 0, 1],\n",
              " (5.6, 2.8, 4.9, 2.0): [0, 0, 1],\n",
              " (5.8, 2.6, 4.0, 1.2): [0, 1, 0],\n",
              " (5.8, 2.7, 4.1, 1.0): [0, 1, 0],\n",
              " (4.7, 3.2, 1.6, 0.2): [1, 0, 0],\n",
              " (6.2, 2.8, 4.8, 1.8): [0, 0, 1],\n",
              " (6.8, 3.2, 5.9, 2.3): [0, 0, 1],\n",
              " (5.6, 2.5, 3.9, 1.1): [0, 1, 0],\n",
              " (5.7, 3.8, 1.7, 0.3): [1, 0, 0],\n",
              " (5.3, 3.7, 1.5, 0.2): [1, 0, 0],\n",
              " (5.7, 4.4, 1.5, 0.4): [1, 0, 0],\n",
              " (7.4, 2.8, 6.1, 1.9): [0, 0, 1],\n",
              " (6.1, 3.0, 4.6, 1.4): [0, 1, 0],\n",
              " (7.0, 3.2, 4.7, 1.4): [0, 1, 0],\n",
              " (5.7, 2.9, 4.2, 1.3): [0, 1, 0],\n",
              " (6.3, 2.8, 5.1, 1.5): [0, 0, 1],\n",
              " (5.8, 4.0, 1.2, 0.2): [1, 0, 0],\n",
              " (4.9, 3.6, 1.4, 0.1): [1, 0, 0],\n",
              " (6.5, 3.0, 5.2, 2.0): [0, 0, 1],\n",
              " (5.7, 2.5, 5.0, 2.0): [0, 0, 1],\n",
              " (5.6, 3.0, 4.1, 1.3): [0, 1, 0],\n",
              " (6.0, 3.4, 4.5, 1.6): [0, 1, 0],\n",
              " (5.5, 3.5, 1.3, 0.2): [1, 0, 0],\n",
              " (5.9, 3.0, 5.1, 1.8): [0, 0, 1],\n",
              " (4.9, 2.5, 4.5, 1.7): [0, 0, 1],\n",
              " (6.4, 2.8, 5.6, 2.1): [0, 0, 1],\n",
              " (7.6, 3.0, 6.6, 2.1): [0, 0, 1],\n",
              " (6.7, 3.0, 5.0, 1.7): [0, 1, 0],\n",
              " (5.0, 3.0, 1.6, 0.2): [1, 0, 0],\n",
              " (5.4, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (5.2, 3.5, 1.5, 0.2): [1, 0, 0],\n",
              " (7.1, 3.0, 5.9, 2.1): [0, 0, 1],\n",
              " (5.1, 3.8, 1.9, 0.4): [1, 0, 0],\n",
              " (7.7, 3.0, 6.1, 2.3): [0, 0, 1],\n",
              " (6.4, 3.2, 5.3, 2.3): [0, 0, 1],\n",
              " (5.1, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.5, 1.3, 0.3): [1, 0, 0],\n",
              " (6.8, 2.8, 4.8, 1.4): [0, 1, 0],\n",
              " (6.3, 3.4, 5.6, 2.4): [0, 0, 1],\n",
              " (6.0, 3.0, 4.8, 1.8): [0, 0, 1],\n",
              " (5.5, 2.6, 4.4, 1.2): [0, 1, 0],\n",
              " (4.7, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (5.7, 2.6, 3.5, 1.0): [0, 1, 0],\n",
              " (5.5, 4.2, 1.4, 0.2): [1, 0, 0],\n",
              " (4.4, 3.0, 1.3, 0.2): [1, 0, 0],\n",
              " (6.6, 3.0, 4.4, 1.4): [0, 1, 0],\n",
              " (4.6, 3.4, 1.4, 0.3): [1, 0, 0],\n",
              " (5.4, 3.4, 1.5, 0.4): [1, 0, 0],\n",
              " (4.8, 3.1, 1.6, 0.2): [1, 0, 0],\n",
              " (6.1, 2.9, 4.7, 1.4): [0, 1, 0],\n",
              " (7.2, 3.2, 6.0, 1.8): [0, 0, 1],\n",
              " (6.0, 2.7, 5.1, 1.6): [0, 1, 0],\n",
              " (6.4, 2.9, 4.3, 1.3): [0, 1, 0],\n",
              " (6.1, 2.6, 5.6, 1.4): [0, 0, 1],\n",
              " (4.9, 3.0, 1.4, 0.2): [1, 0, 0],\n",
              " (6.2, 2.2, 4.5, 1.5): [0, 1, 0],\n",
              " (5.6, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (5.0, 3.6, 1.4, 0.2): [1, 0, 0],\n",
              " (5.2, 2.7, 3.9, 1.4): [0, 1, 0],\n",
              " (6.7, 2.5, 5.8, 1.8): [0, 0, 1],\n",
              " (5.6, 2.9, 3.6, 1.3): [0, 1, 0],\n",
              " (6.5, 3.2, 5.1, 2.0): [0, 0, 1],\n",
              " (4.5, 2.3, 1.3, 0.3): [1, 0, 0],\n",
              " (5.9, 3.2, 4.8, 1.8): [0, 1, 0],\n",
              " (6.3, 2.3, 4.4, 1.3): [0, 1, 0],\n",
              " (7.3, 2.9, 6.3, 1.8): [0, 0, 1],\n",
              " (5.0, 2.3, 3.3, 1.0): [0, 1, 0],\n",
              " (6.5, 3.0, 5.5, 1.8): [0, 0, 1],\n",
              " (6.2, 2.9, 4.3, 1.3): [0, 1, 0],\n",
              " (6.7, 3.1, 4.4, 1.4): [0, 1, 0],\n",
              " (4.8, 3.0, 1.4, 0.1): [1, 0, 0],\n",
              " (6.1, 3.0, 4.9, 1.8): [0, 0, 1],\n",
              " (6.9, 3.1, 5.1, 2.3): [0, 0, 1],\n",
              " (7.9, 3.8, 6.4, 2.0): [0, 0, 1],\n",
              " (5.4, 3.7, 1.5, 0.2): [1, 0, 0],\n",
              " (6.7, 3.0, 5.2, 2.3): [0, 0, 1],\n",
              " (7.7, 2.8, 6.7, 2.0): [0, 0, 1],\n",
              " (6.3, 2.5, 5.0, 1.9): [0, 0, 1],\n",
              " (6.3, 2.5, 4.9, 1.5): [0, 1, 0],\n",
              " (6.2, 3.4, 5.4, 2.3): [0, 0, 1],\n",
              " (6.4, 2.7, 5.3, 1.9): [0, 0, 1],\n",
              " (5.7, 2.8, 4.1, 1.3): [0, 1, 0],\n",
              " (6.9, 3.1, 5.4, 2.1): [0, 0, 1],\n",
              " (4.9, 3.1, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.5, 1.6, 0.6): [1, 0, 0],\n",
              " (5.1, 3.8, 1.5, 0.3): [1, 0, 0],\n",
              " (4.6, 3.2, 1.4, 0.2): [1, 0, 0],\n",
              " (4.3, 3.0, 1.1, 0.1): [1, 0, 0],\n",
              " (6.3, 3.3, 6.0, 2.5): [0, 0, 1],\n",
              " (7.7, 3.8, 6.7, 2.2): [0, 0, 1],\n",
              " (5.4, 3.4, 1.7, 0.2): [1, 0, 0],\n",
              " (5.1, 3.5, 1.4, 0.3): [1, 0, 0],\n",
              " (5.2, 3.4, 1.4, 0.2): [1, 0, 0],\n",
              " (5.7, 2.8, 4.5, 1.3): [0, 1, 0],\n",
              " (6.9, 3.2, 5.7, 2.3): [0, 0, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the split index\n",
        "split_index = int(0.8 * len(data))\n",
        "\n",
        "# Separate the data\n",
        "train_data = dict(list(data.items())[:split_index])\n",
        "test_data = dict(list(data.items())[split_index:])"
      ],
      "metadata": {
        "id": "07A-yOHVGxOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqNBESlHHhx9",
        "outputId": "0a9b269f-ac84-4816-9795-9fe76e13d549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(4.8, 3.4, 1.6, 0.2): [1, 0, 0],\n",
              " (5.4, 3.9, 1.3, 0.4): [1, 0, 0],\n",
              " (5.0, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (6.4, 3.1, 5.5, 1.8): [0, 0, 1],\n",
              " (5.4, 3.9, 1.7, 0.4): [1, 0, 0],\n",
              " (6.3, 2.9, 5.6, 1.8): [0, 0, 1],\n",
              " (6.7, 3.1, 5.6, 2.4): [0, 0, 1],\n",
              " (6.0, 2.2, 4.0, 1.0): [0, 1, 0],\n",
              " (5.6, 2.7, 4.2, 1.3): [0, 1, 0],\n",
              " (5.1, 3.5, 1.4, 0.2): [1, 0, 0],\n",
              " (5.0, 3.2, 1.2, 0.2): [1, 0, 0],\n",
              " (4.9, 3.1, 1.5, 0.1): [1, 0, 0],\n",
              " (6.5, 3.0, 5.8, 2.2): [0, 0, 1],\n",
              " (5.8, 2.8, 5.1, 2.4): [0, 0, 1],\n",
              " (5.5, 2.4, 3.8, 1.1): [0, 1, 0],\n",
              " (5.9, 3.0, 4.2, 1.5): [0, 1, 0],\n",
              " (6.7, 3.1, 4.7, 1.5): [0, 1, 0],\n",
              " (6.8, 3.0, 5.5, 2.1): [0, 0, 1],\n",
              " (6.9, 3.1, 4.9, 1.5): [0, 1, 0],\n",
              " (5.0, 3.4, 1.6, 0.4): [1, 0, 0],\n",
              " (4.9, 2.4, 3.3, 1.0): [0, 1, 0],\n",
              " (5.1, 3.3, 1.7, 0.5): [1, 0, 0],\n",
              " (6.7, 3.3, 5.7, 2.1): [0, 0, 1],\n",
              " (4.8, 3.0, 1.4, 0.3): [1, 0, 0],\n",
              " (6.0, 2.2, 5.0, 1.5): [0, 0, 1],\n",
              " (6.6, 2.9, 4.6, 1.3): [0, 1, 0],\n",
              " (5.0, 3.3, 1.4, 0.2): [1, 0, 0],\n",
              " (6.1, 2.8, 4.0, 1.3): [0, 1, 0],\n",
              " (5.5, 2.4, 3.7, 1.0): [0, 1, 0],\n",
              " (4.4, 2.9, 1.4, 0.2): [1, 0, 0],\n",
              " (6.0, 2.9, 4.5, 1.5): [0, 1, 0],\n",
              " (7.7, 2.6, 6.9, 2.3): [0, 0, 1],\n",
              " (5.7, 3.0, 4.2, 1.2): [0, 1, 0],\n",
              " (7.2, 3.0, 5.8, 1.6): [0, 0, 1],\n",
              " (4.8, 3.4, 1.9, 0.2): [1, 0, 0],\n",
              " (5.0, 2.0, 3.5, 1.0): [0, 1, 0],\n",
              " (4.6, 3.1, 1.5, 0.2): [1, 0, 0],\n",
              " (5.8, 2.7, 3.9, 1.2): [0, 1, 0],\n",
              " (5.8, 2.7, 5.1, 1.9): [0, 0, 1],\n",
              " (6.4, 3.2, 4.5, 1.5): [0, 1, 0],\n",
              " (5.5, 2.5, 4.0, 1.3): [0, 1, 0],\n",
              " (5.1, 3.8, 1.6, 0.2): [1, 0, 0],\n",
              " (6.4, 2.8, 5.6, 2.2): [0, 0, 1],\n",
              " (5.5, 2.3, 4.0, 1.3): [0, 1, 0],\n",
              " (5.1, 2.5, 3.0, 1.1): [0, 1, 0],\n",
              " (5.1, 3.7, 1.5, 0.4): [1, 0, 0],\n",
              " (7.2, 3.6, 6.1, 2.5): [0, 0, 1],\n",
              " (6.5, 2.8, 4.6, 1.5): [0, 1, 0],\n",
              " (6.1, 2.8, 4.7, 1.2): [0, 1, 0],\n",
              " (6.3, 2.7, 4.9, 1.8): [0, 0, 1],\n",
              " (4.4, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (5.2, 4.1, 1.5, 0.1): [1, 0, 0],\n",
              " (4.6, 3.6, 1.0, 0.2): [1, 0, 0],\n",
              " (6.3, 3.3, 4.7, 1.6): [0, 1, 0],\n",
              " (6.7, 3.3, 5.7, 2.5): [0, 0, 1],\n",
              " (5.6, 2.8, 4.9, 2.0): [0, 0, 1],\n",
              " (5.8, 2.6, 4.0, 1.2): [0, 1, 0],\n",
              " (5.8, 2.7, 4.1, 1.0): [0, 1, 0],\n",
              " (4.7, 3.2, 1.6, 0.2): [1, 0, 0],\n",
              " (6.2, 2.8, 4.8, 1.8): [0, 0, 1],\n",
              " (6.8, 3.2, 5.9, 2.3): [0, 0, 1],\n",
              " (5.6, 2.5, 3.9, 1.1): [0, 1, 0],\n",
              " (5.7, 3.8, 1.7, 0.3): [1, 0, 0],\n",
              " (5.3, 3.7, 1.5, 0.2): [1, 0, 0],\n",
              " (5.7, 4.4, 1.5, 0.4): [1, 0, 0],\n",
              " (7.4, 2.8, 6.1, 1.9): [0, 0, 1],\n",
              " (6.1, 3.0, 4.6, 1.4): [0, 1, 0],\n",
              " (7.0, 3.2, 4.7, 1.4): [0, 1, 0],\n",
              " (5.7, 2.9, 4.2, 1.3): [0, 1, 0],\n",
              " (6.3, 2.8, 5.1, 1.5): [0, 0, 1],\n",
              " (5.8, 4.0, 1.2, 0.2): [1, 0, 0],\n",
              " (4.9, 3.6, 1.4, 0.1): [1, 0, 0],\n",
              " (6.5, 3.0, 5.2, 2.0): [0, 0, 1],\n",
              " (5.7, 2.5, 5.0, 2.0): [0, 0, 1],\n",
              " (5.6, 3.0, 4.1, 1.3): [0, 1, 0],\n",
              " (6.0, 3.4, 4.5, 1.6): [0, 1, 0],\n",
              " (5.5, 3.5, 1.3, 0.2): [1, 0, 0],\n",
              " (5.9, 3.0, 5.1, 1.8): [0, 0, 1],\n",
              " (4.9, 2.5, 4.5, 1.7): [0, 0, 1],\n",
              " (6.4, 2.8, 5.6, 2.1): [0, 0, 1],\n",
              " (7.6, 3.0, 6.6, 2.1): [0, 0, 1],\n",
              " (6.7, 3.0, 5.0, 1.7): [0, 1, 0],\n",
              " (5.0, 3.0, 1.6, 0.2): [1, 0, 0],\n",
              " (5.4, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (5.2, 3.5, 1.5, 0.2): [1, 0, 0],\n",
              " (7.1, 3.0, 5.9, 2.1): [0, 0, 1],\n",
              " (5.1, 3.8, 1.9, 0.4): [1, 0, 0],\n",
              " (7.7, 3.0, 6.1, 2.3): [0, 0, 1],\n",
              " (6.4, 3.2, 5.3, 2.3): [0, 0, 1],\n",
              " (5.1, 3.4, 1.5, 0.2): [1, 0, 0],\n",
              " (5.0, 3.5, 1.3, 0.3): [1, 0, 0],\n",
              " (6.8, 2.8, 4.8, 1.4): [0, 1, 0],\n",
              " (6.3, 3.4, 5.6, 2.4): [0, 0, 1],\n",
              " (6.0, 3.0, 4.8, 1.8): [0, 0, 1],\n",
              " (5.5, 2.6, 4.4, 1.2): [0, 1, 0],\n",
              " (4.7, 3.2, 1.3, 0.2): [1, 0, 0],\n",
              " (5.7, 2.6, 3.5, 1.0): [0, 1, 0],\n",
              " (5.5, 4.2, 1.4, 0.2): [1, 0, 0],\n",
              " (4.4, 3.0, 1.3, 0.2): [1, 0, 0],\n",
              " (6.6, 3.0, 4.4, 1.4): [0, 1, 0],\n",
              " (4.6, 3.4, 1.4, 0.3): [1, 0, 0],\n",
              " (5.4, 3.4, 1.5, 0.4): [1, 0, 0],\n",
              " (4.8, 3.1, 1.6, 0.2): [1, 0, 0],\n",
              " (6.1, 2.9, 4.7, 1.4): [0, 1, 0],\n",
              " (7.2, 3.2, 6.0, 1.8): [0, 0, 1],\n",
              " (6.0, 2.7, 5.1, 1.6): [0, 1, 0],\n",
              " (6.4, 2.9, 4.3, 1.3): [0, 1, 0],\n",
              " (6.1, 2.6, 5.6, 1.4): [0, 0, 1],\n",
              " (4.9, 3.0, 1.4, 0.2): [1, 0, 0],\n",
              " (6.2, 2.2, 4.5, 1.5): [0, 1, 0],\n",
              " (5.6, 3.0, 4.5, 1.5): [0, 1, 0],\n",
              " (5.0, 3.6, 1.4, 0.2): [1, 0, 0],\n",
              " (5.2, 2.7, 3.9, 1.4): [0, 1, 0],\n",
              " (6.7, 2.5, 5.8, 1.8): [0, 0, 1],\n",
              " (5.6, 2.9, 3.6, 1.3): [0, 1, 0],\n",
              " (6.5, 3.2, 5.1, 2.0): [0, 0, 1],\n",
              " (4.5, 2.3, 1.3, 0.3): [1, 0, 0],\n",
              " (5.9, 3.2, 4.8, 1.8): [0, 1, 0],\n",
              " (6.3, 2.3, 4.4, 1.3): [0, 1, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ***writing the model that evolves on its own***"
      ],
      "metadata": {
        "id": "ppPlYBnQIwe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code to define my structure and initialise it**"
      ],
      "metadata": {
        "id": "QheDEekfPeVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initial wight initialization\n",
        "\n",
        "def initial_xavier_initialization(input_weight_dmin, output_weight_dmin, input_bias_dmin, output_bias_dmin):\n",
        "  W = []\n",
        "  B = []\n",
        "\n",
        "  delta = [[0 for i in range(x)] for x in output_bias_dmin]\n",
        "  n_hidden_layers = len(input_weight_dmin)-1\n",
        "\n",
        "  #for weight matrix\n",
        "  for i in range(len(input_weight_dmin)):\n",
        "    n_in = input_weight_dmin[i]\n",
        "    n_out = output_weight_dmin[i]\n",
        "\n",
        "    limit = np.sqrt(6) / np.sqrt(n_in + n_out)\n",
        "    W.append(tf.random.uniform((n_in, n_out), minval=-limit, maxval=limit))\n",
        "\n",
        "  #for bias matirx\n",
        "  for i in range(len(input_bias_dmin)):\n",
        "    n_in = input_bias_dmin[i]\n",
        "    n_out = output_bias_dmin[i]\n",
        "\n",
        "    limit = np.sqrt(6) / np.sqrt(n_in + n_out)\n",
        "    B.append(tf.random.uniform((1, n_out), minval=-limit, maxval=limit))\n",
        "\n",
        "  return W, B, delta, n_hidden_layers\n"
      ],
      "metadata": {
        "id": "Tkr6sHjmIsN5"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining my activation functions and their derivatives**"
      ],
      "metadata": {
        "id": "sF_uDgjKO0Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining activation functions relu and softmax\n",
        "\n",
        "def relu(x):\n",
        "  for i in range(len(x)):\n",
        "    x[i] = np.maximum(x[i], 0)\n",
        "  return x\n",
        "\n",
        "def softmax(x):\n",
        "  for i in range(len(x)):\n",
        "    x[i] = np.exp(x[i])\n",
        "  return np.divide(x,sum(x))"
      ],
      "metadata": {
        "id": "Pqv2taxRNFzb"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Derivative of ReLU and softmax\n",
        "\n",
        "def softmax_derivative(x):\n",
        "  Jacobian = []\n",
        "  for i in range(len(x)):\n",
        "    temp = []\n",
        "    for j in range(len(x)):\n",
        "      if i == j:\n",
        "        temp.append(x[i]*(1-x[i]))\n",
        "      else:\n",
        "        temp.append(-x[i]*x[j])\n",
        "    Jacobian.append(temp)\n",
        "  Jacobian = np.array(Jacobian)\n",
        "  return Jacobian.T\n",
        "\n",
        "def ReLU_derivative(x):\n",
        "  for i in range(len(x)):\n",
        "    if x[i] > 0:\n",
        "      x[i] = 1\n",
        "    else:\n",
        "      x[i] = 0\n",
        "  return x"
      ],
      "metadata": {
        "id": "U1nY7apzPGCq"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This network is based on mini-batch gradient descent**"
      ],
      "metadata": {
        "id": "gmkU8VLdTUm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minibatch(batch_size,epoch,train_data,delta,learning_rate,n_hidden_layers):\n",
        "\n",
        "  for e in range(epoch):\n",
        "    print(\"Epcoh:\",e+1)\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    no_of_batches = 6-1\n",
        "    batch_size = len(train_data)//no_of_batches\n",
        "\n",
        "    batches = []\n",
        "    train_data = shuffle_dict(train_data)\n",
        "    i=0\n",
        "    j=0\n",
        "    while(i<len(train_data)):\n",
        "      j+=1\n",
        "      batches.append(dict(list(train_data.items())[i:i+batch_size]))\n",
        "      i += batch_size\n",
        "    for batch in batches:\n",
        "      result = minibatchmodel(delta,batch,learning_rate,n_hidden_layers)\n",
        "      if result != None:\n",
        "        loss = loss + result[0]\n",
        "        accuracy = accuracy + result[1]\n",
        "\n",
        "    print(loss/len(batches),accuracy/len(batches))"
      ],
      "metadata": {
        "id": "C5x_HqgENZmE"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minibatchmodel(delta,batch,learning_rate,n_hidden_layers):\n",
        "  batch_output = []\n",
        "  batch_actual_output = []\n",
        "  for i in batch:\n",
        "    output = []\n",
        "    output.append(list(i))\n",
        "    batch_output.append(forward_propagation(W,B,0,n_hidden_layers,[list(i)],output))\n",
        "    batch_actual_output.append(batch[i])\n",
        "  loss, accruracy = mean_squared_loss(batch_actual_output,[batch_output[x][-1] for x in range(len(batch_output))])\n",
        "  backward_propagation(W,B,delta,n_hidden_layers,n_hidden_layers,batch_output,batch_actual_output,learning_rate)\n",
        "  return loss,accruracy"
      ],
      "metadata": {
        "id": "9XkTPyCRRVHK"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(W,B,N,n_hidden_layers,input,output):\n",
        "  if N == n_hidden_layers:\n",
        "    input = softmax(np.add(np.dot(input,W[N]),B[N])[0])\n",
        "    output.append(input)\n",
        "    return output\n",
        "  else:\n",
        "    input = relu(np.add(np.dot(input,W[N]),B[N])[0])\n",
        "    output.append(input)\n",
        "\n",
        "    return forward_propagation(W,B,N+1,n_hidden_layers,input[0],output)\n"
      ],
      "metadata": {
        "id": "VpNgzQyRUbA0"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(W,B,delta,N,n_hidden_layers,batch_output,actual_output,learning_rate):\n",
        "  if N == 0:\n",
        "    derivative = ReLU_derivative(batch_output[0][N+1])\n",
        "    previous_input = batch_output[0][N]\n",
        "    for i in range(1,len(batch_output)):\n",
        "      derivative = np.add(derivative,ReLU_derivative(batch_output[i][N+1]))\n",
        "      previous_input = np.add(previous_input,batch_output[i][N])\n",
        "    derivative = np.divide(derivative,len(batch_output))\n",
        "    previous_input = np.divide(previous_input,len(batch_output))\n",
        "    delta[N] = np.multiply(derivative,delta[N])\n",
        "    change_in_B = delta[N]\n",
        "    change_in_W = np.dot(np.array([previous_input]).T,np.array([delta[N]]))\n",
        "\n",
        "    W[N] = W[N] - np.dot(learning_rate,change_in_W)\n",
        "    B[N] = B[N] - np.dot(learning_rate,change_in_B)\n",
        "\n",
        "    return 1\n",
        "  elif N==n_hidden_layers:\n",
        "\n",
        "    error = np.subtract(batch_output[0][N+1],actual_output[0])\n",
        "    derivative = softmax_derivative(batch_output[0][N+1])\n",
        "    previous_input = batch_output[0][N]\n",
        "    for i in range(1,len(batch_output)):\n",
        "      error = np.add(error,np.subtract(batch_output[i][N+1],actual_output[i]))\n",
        "      derivative = np.add(derivative,softmax_derivative(batch_output[i][N+1]))\n",
        "      previous_input = np.add(previous_input,batch_output[i][N])\n",
        "    error = np.divide(error,len(batch_output))\n",
        "    derivative = np.divide(derivative,len(batch_output))\n",
        "    previous_input = np.divide(previous_input,len(batch_output))\n",
        "    delta[N] = np.dot(error,derivative)\n",
        "    change_in_B = delta[N]\n",
        "    change_in_W = np.dot(np.array([previous_input]).T,np.array([delta[N]]))\n",
        "    delta[N-1] = np.dot(delta[N],np.array(W[N]).T)\n",
        "  else:\n",
        "\n",
        "    derivative = ReLU_derivative(batch_output[0][N+1])\n",
        "    previous_input = batch_output[0][N]\n",
        "    for i in range(1,len(batch_output)):\n",
        "      derivative = np.add(derivative,ReLU_derivative(batch_output[i][N+1]))\n",
        "      previous_input = np.add(previous_input,batch_output[i][N])\n",
        "    derivative = np.divide(derivative,len(batch_output))\n",
        "    previous_input = np.divide(previous_input,len(batch_output))\n",
        "    delta[N] = np.multiply(derivative,delta[N])\n",
        "    change_in_B = delta[N]\n",
        "    change_in_W = np.dot(np.array([previous_input]).T,np.array([delta[N]]))\n",
        "    delta[N-1] = np.dot(delta[N],np.array(W[N]).T)\n",
        "\n",
        "  W[N] = W[N] - np.dot(learning_rate,change_in_W)\n",
        "  B[N] = B[N] - np.dot(learning_rate,change_in_B)\n",
        "\n",
        "\n",
        "  return backward_propagation(W,B,delta,N-1,n_hidden_layers,batch_output,actual_output,learning_rate)"
      ],
      "metadata": {
        "id": "hNTPJFpDWKTd"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_data):\n",
        "  output = []\n",
        "  for i in test_data:\n",
        "    output.append(forward_propagation(W,B,0,n_hidden_layers,[list(i)],[])[-1])\n",
        "  return output"
      ],
      "metadata": {
        "id": "gjN0jW69Bk0h"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = predict(test_data)\n",
        "mean_squared_loss(list(test_data.values()),predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuxNceWICLyK",
        "outputId": "62ae9dec-1c9e-4ddb-deb2-ff2a172a33f8"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2341954766270167, 0.7658045233729833)"
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_loss(actual, predicted):\n",
        "    actual = np.array(actual)\n",
        "    predicted = np.array(predicted)\n",
        "    loss = np.mean(np.square(actual - predicted))\n",
        "    return loss,1-loss"
      ],
      "metadata": {
        "id": "zQ81SxCACp0S"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THE MAIN CODE**"
      ],
      "metadata": {
        "id": "WjjlD3faKSs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the split index\n",
        "split_index = int(0.8 * len(data))\n",
        "\n",
        "# Separate the data\n",
        "train_data = dict(list(data.items())[:split_index])\n",
        "test_data = dict(list(data.items())[split_index:])"
      ],
      "metadata": {
        "id": "fn9S4AeIKtQ0"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_weight_dmin = [np.array(list(data.keys())[0]).shape[0],64,128,128,64]\n",
        "output_weight_dmin = [64,128,128,64,np.array(list(data.values())[0]).shape[0]]\n",
        "input_bias_dmin = [64,128,128,64,np.array(list(data.values())[0]).shape[0]]\n",
        "output_bias_dmin = [64,128,128,64,np.array(list(data.values())[0]).shape[0]]"
      ],
      "metadata": {
        "id": "S_rTwyApKpK5"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W,B,delta,n_hidden_layers = initial_xavier_initialization(input_weight_dmin, output_weight_dmin, input_bias_dmin, output_bias_dmin)"
      ],
      "metadata": {
        "id": "eAFT7sF0KXVa"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epoch = 200\n",
        "learning_rate = 0.001\n",
        "minibatch(batch_size,epoch,train_data,delta,learning_rate,n_hidden_layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC7o6rgQDwyd",
        "outputId": "979af63e-2e26-49e7-e85a-4d7124c07532"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epcoh: 1\n",
            "0.2205997353509402 0.7794002646490598\n",
            "Epcoh: 2\n",
            "0.22059947321098397 0.779400526789016\n",
            "Epcoh: 3\n",
            "0.22164947642121025 0.7783505235787898\n",
            "Epcoh: 4\n",
            "0.21978248989247542 0.7802175101075246\n",
            "Epcoh: 5\n",
            "0.21955172167120326 0.7804482783287967\n",
            "Epcoh: 6\n",
            "0.22246675507282568 0.7775332449271742\n",
            "Epcoh: 7\n",
            "0.22164927542326032 0.7783507245767397\n",
            "Epcoh: 8\n",
            "0.22059928440808207 0.7794007155919179\n",
            "Epcoh: 9\n",
            "0.22269761779489097 0.777302382205109\n",
            "Epcoh: 10\n",
            "0.21978165751068465 0.7802183424893153\n",
            "Epcoh: 11\n",
            "0.22351273498578803 0.776487265014212\n",
            "Epcoh: 12\n",
            "0.22246505204981912 0.7775349479501809\n",
            "Epcoh: 13\n",
            "0.2226900188480486 0.7773099811519514\n",
            "Epcoh: 14\n",
            "0.21978095307432843 0.7802190469256716\n",
            "Epcoh: 15\n",
            "0.21978071647718536 0.7802192835228147\n",
            "Epcoh: 16\n",
            "0.22246518144994307 0.7775348185500569\n",
            "Epcoh: 17\n",
            "0.22328672781482892 0.7767132721851709\n",
            "Epcoh: 18\n",
            "0.22350561185059772 0.7764943881494023\n",
            "Epcoh: 19\n",
            "0.22082243191542383 0.7791775680845762\n",
            "Epcoh: 20\n",
            "0.22164156337493934 0.7783584366250608\n",
            "Epcoh: 21\n",
            "0.22164047628839975 0.7783595237116002\n",
            "Epcoh: 22\n",
            "0.22267873366366597 0.777321266336334\n",
            "Epcoh: 23\n",
            "0.22163828141492778 0.7783617185850723\n",
            "Epcoh: 24\n",
            "0.2224622334090962 0.7775377665909037\n",
            "Epcoh: 25\n",
            "0.22163762611368276 0.7783623738863171\n",
            "Epcoh: 26\n",
            "0.22060375175627703 0.779396248243723\n",
            "Epcoh: 27\n",
            "0.2216370025091976 0.7783629974908024\n",
            "Epcoh: 28\n",
            "0.22163750368197885 0.7783624963180212\n",
            "Epcoh: 29\n",
            "0.22246144243557256 0.7775385575644274\n",
            "Epcoh: 30\n",
            "0.22163583064912998 0.77836416935087\n",
            "Epcoh: 31\n",
            "0.22431739917102156 0.7756826008289787\n",
            "Epcoh: 32\n",
            "0.22163500371010858 0.7783649962898914\n",
            "Epcoh: 33\n",
            "0.22245943829738443 0.7775405617026157\n",
            "Epcoh: 34\n",
            "0.22060538116545347 0.7793946188345465\n",
            "Epcoh: 35\n",
            "0.22163497064746848 0.7783650293525315\n",
            "Epcoh: 36\n",
            "0.22080827578606366 0.7791917242139363\n",
            "Epcoh: 37\n",
            "0.22245925678507297 0.7775407432149269\n",
            "Epcoh: 38\n",
            "0.2206055978818602 0.7793944021181397\n",
            "Epcoh: 39\n",
            "0.21957915194327157 0.7804208480567284\n",
            "Epcoh: 40\n",
            "0.22060578654462837 0.7793942134553716\n",
            "Epcoh: 41\n",
            "0.22246010849152795 0.777539891508472\n",
            "Epcoh: 42\n",
            "0.2206053276088528 0.7793946723911472\n",
            "Epcoh: 43\n",
            "0.22245895283493367 0.7775410471650663\n",
            "Epcoh: 44\n",
            "0.22163342724599597 0.778366572754004\n",
            "Epcoh: 45\n",
            "0.22163289311639198 0.778367106883608\n",
            "Epcoh: 46\n",
            "0.21957979543939624 0.7804202045606038\n",
            "Epcoh: 47\n",
            "0.2208082717176314 0.7791917282823686\n",
            "Epcoh: 48\n",
            "0.22080559769783603 0.779194402302164\n",
            "Epcoh: 49\n",
            "0.22060589262925898 0.779394107370741\n",
            "Epcoh: 50\n",
            "0.2216313296304259 0.778368670369574\n",
            "Epcoh: 51\n",
            "0.2226560824586484 0.7773439175413516\n",
            "Epcoh: 52\n",
            "0.22245927950116764 0.7775407204988324\n",
            "Epcoh: 53\n",
            "0.22245877821014592 0.777541221789854\n",
            "Epcoh: 54\n",
            "0.22348100134329063 0.7765189986567095\n",
            "Epcoh: 55\n",
            "0.22245681755518998 0.77754318244481\n",
            "Epcoh: 56\n",
            "0.22060767268289794 0.779392327317102\n",
            "Epcoh: 57\n",
            "0.22182176041144816 0.778178239588552\n",
            "Epcoh: 58\n",
            "0.2216261849823388 0.7783738150176612\n",
            "Epcoh: 59\n",
            "0.22060793037816553 0.7793920696218345\n",
            "Epcoh: 60\n",
            "0.22245737217745576 0.7775426278225442\n",
            "Epcoh: 61\n",
            "0.21876060512222328 0.7812393948777768\n",
            "Epcoh: 62\n",
            "0.22162614589504445 0.7783738541049555\n",
            "Epcoh: 63\n",
            "0.22162571072292914 0.778374289277071\n",
            "Epcoh: 64\n",
            "0.22347396999668825 0.7765260300033116\n",
            "Epcoh: 65\n",
            "0.21876259981215532 0.7812374001878447\n",
            "Epcoh: 66\n",
            "0.22060848182735104 0.7793915181726491\n",
            "Epcoh: 67\n",
            "0.22245750371413875 0.7775424962858613\n",
            "Epcoh: 68\n",
            "0.22162472606891812 0.7783752739310819\n",
            "Epcoh: 69\n",
            "0.22430539148196785 0.7756946085180322\n",
            "Epcoh: 70\n",
            "0.22144147906226977 0.7785585209377301\n",
            "Epcoh: 71\n",
            "0.22060857296452752 0.7793914270354726\n",
            "Epcoh: 72\n",
            "0.22143953306998862 0.7785604669300114\n",
            "Epcoh: 73\n",
            "0.21876313732413308 0.7812368626758669\n",
            "Epcoh: 74\n",
            "0.2214386778916797 0.7785613221083203\n",
            "Epcoh: 75\n",
            "0.21876099588002162 0.7812390041199784\n",
            "Epcoh: 76\n",
            "0.2214375607391087 0.7785624392608913\n",
            "Epcoh: 77\n",
            "0.22264831708448726 0.7773516829155128\n",
            "Epcoh: 78\n",
            "0.22264506984245155 0.7773549301575485\n",
            "Epcoh: 79\n",
            "0.219593332064712 0.780406667935288\n",
            "Epcoh: 80\n",
            "0.22328612751722743 0.7767138724827726\n",
            "Epcoh: 81\n",
            "0.2224548704258281 0.7775451295741719\n",
            "Epcoh: 82\n",
            "0.22143689624116888 0.7785631037588311\n",
            "Epcoh: 83\n",
            "0.21978187707397545 0.7802181229260245\n",
            "Epcoh: 84\n",
            "0.2206082374267994 0.7793917625732005\n",
            "Epcoh: 85\n",
            "0.22245567297041327 0.7775443270295866\n",
            "Epcoh: 86\n",
            "0.21959027460382166 0.7804097253961784\n",
            "Epcoh: 87\n",
            "0.22264881510418855 0.7773511848958115\n",
            "Epcoh: 88\n",
            "0.21959094344410332 0.7804090565558967\n",
            "Epcoh: 89\n",
            "0.2206079514323458 0.7793920485676543\n",
            "Epcoh: 90\n",
            "0.22264869427592635 0.7773513057240736\n",
            "Epcoh: 91\n",
            "0.22264437875328844 0.7773556212467114\n",
            "Epcoh: 92\n",
            "0.2187644782747924 0.7812355217252076\n",
            "Epcoh: 93\n",
            "0.22162581232265036 0.7783741876773496\n",
            "Epcoh: 94\n",
            "0.22347171337032337 0.7765282866296767\n",
            "Epcoh: 95\n",
            "0.22060925726903788 0.7793907427309622\n",
            "Epcoh: 96\n",
            "0.21977931653065028 0.7802206834693498\n",
            "Epcoh: 97\n",
            "0.2206089923750254 0.7793910076249747\n",
            "Epcoh: 98\n",
            "0.22060980835363578 0.7793901916463642\n",
            "Epcoh: 99\n",
            "0.2216239532166221 0.7783760467833779\n",
            "Epcoh: 100\n",
            "0.2232878101573813 0.7767121898426187\n",
            "Epcoh: 101\n",
            "0.2224544188540368 0.7775455811459633\n",
            "Epcoh: 102\n",
            "0.22162321623878278 0.7783767837612171\n",
            "Epcoh: 103\n",
            "0.22245391737807996 0.77754608262192\n",
            "Epcoh: 104\n",
            "0.2197796835373088 0.7802203164626912\n",
            "Epcoh: 105\n",
            "0.22245439172515039 0.7775456082748495\n",
            "Epcoh: 106\n",
            "0.22144101330325014 0.7785589866967499\n",
            "Epcoh: 107\n",
            "0.22245387053167817 0.7775461294683218\n",
            "Epcoh: 108\n",
            "0.22162310764519821 0.7783768923548018\n",
            "Epcoh: 109\n",
            "0.21978009627708905 0.780219903722911\n",
            "Epcoh: 110\n",
            "0.22245343192020137 0.7775465680797985\n",
            "Epcoh: 111\n",
            "0.2207922283744732 0.7792077716255269\n",
            "Epcoh: 112\n",
            "0.22061037017549187 0.7793896298245081\n",
            "Epcoh: 113\n",
            "0.22061082053475645 0.7793891794652437\n",
            "Epcoh: 114\n",
            "0.22346488779836837 0.7765351122016316\n",
            "Epcoh: 115\n",
            "0.22162040364728872 0.7783795963527114\n",
            "Epcoh: 116\n",
            "0.22245259588638397 0.777547404113616\n",
            "Epcoh: 117\n",
            "0.22245167270485375 0.7775483272951463\n",
            "Epcoh: 118\n",
            "0.22162009524485174 0.7783799047551483\n",
            "Epcoh: 119\n",
            "0.22245121347235863 0.7775487865276415\n",
            "Epcoh: 120\n",
            "0.22262702118285205 0.777372978817148\n",
            "Epcoh: 121\n",
            "0.21978000974202816 0.7802199902579718\n",
            "Epcoh: 122\n",
            "0.2206125278807055 0.7793874721192945\n",
            "Epcoh: 123\n",
            "0.2206123316137798 0.7793876683862201\n",
            "Epcoh: 124\n",
            "0.2224513455755627 0.7775486544244373\n",
            "Epcoh: 125\n",
            "0.22429040498128897 0.7757095950187111\n",
            "Epcoh: 126\n",
            "0.21960949369237306 0.780390506307627\n",
            "Epcoh: 127\n",
            "0.2206123742825821 0.779387625717418\n",
            "Epcoh: 128\n",
            "0.22328307146608295 0.7767169285339172\n",
            "Epcoh: 129\n",
            "0.21877640747553237 0.7812235925244676\n",
            "Epcoh: 130\n",
            "0.21960515128182012 0.7803948487181799\n",
            "Epcoh: 131\n",
            "0.22245075044416515 0.7775492495558348\n",
            "Epcoh: 132\n",
            "0.21877414592966118 0.7812258540703388\n",
            "Epcoh: 133\n",
            "0.2224508816631793 0.7775491183368205\n",
            "Epcoh: 134\n",
            "0.22263041371136472 0.7773695862886353\n",
            "Epcoh: 135\n",
            "0.22144377138978588 0.7785562286102142\n",
            "Epcoh: 136\n",
            "0.22428812643869553 0.7757118735613044\n",
            "Epcoh: 137\n",
            "0.22144149204057165 0.7785585079594283\n",
            "Epcoh: 138\n",
            "0.2224486584447394 0.7775513415552605\n",
            "Epcoh: 139\n",
            "0.22144132095663416 0.7785586790433658\n",
            "Epcoh: 140\n",
            "0.21978566901387966 0.7802143309861203\n",
            "Epcoh: 141\n",
            "0.221621162572197 0.778378837427803\n",
            "Epcoh: 142\n",
            "0.21978463560301872 0.7802153643969811\n",
            "Epcoh: 143\n",
            "0.21960501949625558 0.7803949805037443\n",
            "Epcoh: 144\n",
            "0.22162069938574 0.77837930061426\n",
            "Epcoh: 145\n",
            "0.22161974321474423 0.7783802567852557\n",
            "Epcoh: 146\n",
            "0.22244988483393616 0.7775501151660639\n",
            "Epcoh: 147\n",
            "0.2216198281414461 0.7783801718585539\n",
            "Epcoh: 148\n",
            "0.22061284040944715 0.7793871595905527\n",
            "Epcoh: 149\n",
            "0.21960649241608024 0.7803935075839199\n",
            "Epcoh: 150\n",
            "0.22144081269830365 0.7785591873016964\n",
            "Epcoh: 151\n",
            "0.2207939593679423 0.7792060406320577\n",
            "Epcoh: 152\n",
            "0.22162019310869296 0.7783798068913069\n",
            "Epcoh: 153\n",
            "0.2206123305164942 0.7793876694835058\n",
            "Epcoh: 154\n",
            "0.22244926370551324 0.7775507362944868\n",
            "Epcoh: 155\n",
            "0.22061236731871003 0.77938763268129\n",
            "Epcoh: 156\n",
            "0.22244901669398032 0.7775509833060196\n",
            "Epcoh: 157\n",
            "0.2206124319295809 0.779387568070419\n",
            "Epcoh: 158\n",
            "0.22244873484063357 0.7775512651593665\n",
            "Epcoh: 159\n",
            "0.2216192161164128 0.7783807838835871\n",
            "Epcoh: 160\n",
            "0.22244843068892609 0.7775515693110738\n",
            "Epcoh: 161\n",
            "0.22327657552036748 0.7767234244796325\n",
            "Epcoh: 162\n",
            "0.22262574989002296 0.7773742501099772\n",
            "Epcoh: 163\n",
            "0.2214424328537633 0.7785575671462367\n",
            "Epcoh: 164\n",
            "0.2196090755433473 0.7803909244566527\n",
            "Epcoh: 165\n",
            "0.2206128403743569 0.7793871596256431\n",
            "Epcoh: 166\n",
            "0.221619609801296 0.778380390198704\n",
            "Epcoh: 167\n",
            "0.2224464802380628 0.7775535197619372\n",
            "Epcoh: 168\n",
            "0.22161918928672977 0.7783808107132701\n",
            "Epcoh: 169\n",
            "0.222446135157402 0.777553864842598\n",
            "Epcoh: 170\n",
            "0.21978678400524324 0.7802132159947567\n",
            "Epcoh: 171\n",
            "0.223450634007662 0.7765493659923379\n",
            "Epcoh: 172\n",
            "0.21961177452481206 0.780388225475188\n",
            "Epcoh: 173\n",
            "0.224278206733298 0.775721793266702\n",
            "Epcoh: 174\n",
            "0.2224447325030868 0.7775552674969132\n",
            "Epcoh: 175\n",
            "0.22061468768874715 0.7793853123112529\n",
            "Epcoh: 176\n",
            "0.21978832782940647 0.7802116721705935\n",
            "Epcoh: 177\n",
            "0.22061461115853784 0.7793853888414622\n",
            "Epcoh: 178\n",
            "0.2216174951220994 0.7783825048779005\n",
            "Epcoh: 179\n",
            "0.22061428919110113 0.7793857108088988\n",
            "Epcoh: 180\n",
            "0.21878407643449782 0.7812159235655022\n",
            "Epcoh: 181\n",
            "0.22244613000180624 0.7775538699981938\n",
            "Epcoh: 182\n",
            "0.21878342118718008 0.7812165788128199\n",
            "Epcoh: 183\n",
            "0.2196097595782294 0.7803902404217706\n",
            "Epcoh: 184\n",
            "0.22061271029387178 0.7793872897061283\n",
            "Epcoh: 185\n",
            "0.22262716044039368 0.7773728395596063\n",
            "Epcoh: 186\n",
            "0.2234517321662789 0.7765482678337211\n",
            "Epcoh: 187\n",
            "0.21878272351994776 0.7812172764800523\n",
            "Epcoh: 188\n",
            "0.21961023500939744 0.7803897649906025\n",
            "Epcoh: 189\n",
            "0.21960754333600985 0.7803924566639902\n",
            "Epcoh: 190\n",
            "0.21877781049267497 0.7812221895073249\n",
            "Epcoh: 191\n",
            "0.22162049202300638 0.7783795079769936\n",
            "Epcoh: 192\n",
            "0.22144116454161344 0.7785588354583867\n",
            "Epcoh: 193\n",
            "0.22262947702820488 0.7773705229717951\n",
            "Epcoh: 194\n",
            "0.22244823356951704 0.777551766430483\n",
            "Epcoh: 195\n",
            "0.2216191870047289 0.7783808129952711\n",
            "Epcoh: 196\n",
            "0.22244768392147715 0.7775523160785229\n",
            "Epcoh: 197\n",
            "0.22244735153693784 0.7775526484630624\n",
            "Epcoh: 198\n",
            "0.2207903107180141 0.779209689281986\n",
            "Epcoh: 199\n",
            "0.22161785561019834 0.7783821443898017\n",
            "Epcoh: 200\n",
            "0.22244650393461673 0.7775534960653833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = predict(test_data)\n",
        "mean_squared_loss(list(test_data.values()),predicted)"
      ],
      "metadata": {
        "id": "qaqwEA9yDy0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cd68f1-2ecd-4b04-850c-9a8341fff7e9"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2307802647688784, 0.7692197352311216)"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOGLYX6qUoP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}